# api/api.py

"""
FastAPI application for KYC verification service.
FIXED: Missing config import + response format for frontend
"""

import asyncio
import time
from contextlib import asynccontextmanager
from typing import Optional

from fastapi import FastAPI, File, UploadFile, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import cv2
import numpy as np

# âœ… FIX #1: Added missing import
from configs.config import config
from api.schemas import (
    KYCVerificationResponse,
    OCROnlyResponse,
    ErrorResponse,
    HealthCheckResponse,
    ModelStatus,
    VerificationStatus,
    OCRData,
    OCRFields,
    FaceMatchData,
    SimilarityMetrics,
    ChallengeResponse,
    ChallengeStatus,
    LivenessVerificationRequest,
    LivenessVerificationResponse,
    LivenessBatchRequest,
    LivenessBatchResponse,
)
# âœ… LAZY IMPORT: Don't import ML libraries at module level
# They will be imported inside functions only when needed
# This allows the server to start even if ML libraries fail
from utils.logger import get_logger

logger = get_logger(__name__, log_file="api.log")

# Global service instances (type hints will be resolved at runtime)
face_detector = None
face_matcher = None
ocr_extractor = None
liveness_detector = None  # Liveness detection service
ml_import_error: Optional[str] = None  # Track if ML libraries failed to import

# Semaphore to limit concurrent processing
MAX_CONCURRENT = config.get("processing", "max_concurrent_requests", default=10)
processing_semaphore = asyncio.Semaphore(MAX_CONCURRENT)


# ============================================================================
# Lifespan Event Handler
# ============================================================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Load models at startup, cleanup at shutdown."""
    global face_detector, face_matcher, ocr_extractor, liveness_detector, ml_import_error
    
    logger.info("ðŸš€ Starting KYC Verification Service...")
    
    try:
        # âœ… LAZY IMPORT: Import ML libraries here, not at module level
        logger.info("Importing ML libraries...")
        
        # Try importing onnxruntime directly to see the real error
        try:
            import onnxruntime as ort
            logger.info(f"âœ“ onnxruntime imported successfully (version: {ort.__version__})")
        except Exception as ort_error:
            logger.error(f"âŒ onnxruntime import failed: {type(ort_error).__name__}: {ort_error}")
            raise ImportError(f"onnxruntime failed: {ort_error}")
        
        from app.services.face_detector_id import get_face_detector
        from app.services.face_matcher import get_face_matcher
        from app.services.ocr_extractor import get_ocr_extractor
        logger.info("âœ“ ML libraries imported")
        
        logger.info("Loading face detector...")
        face_detector = await asyncio.to_thread(get_face_detector)
        logger.info("âœ“ Face detector loaded")
        
        logger.info("Loading face matcher...")
        face_matcher = await asyncio.to_thread(get_face_matcher)
        logger.info("âœ“ Face matcher loaded")
        
        logger.info("Loading OCR extractor...")
        ocr_extractor = await asyncio.to_thread(get_ocr_extractor)
        logger.info("âœ“ OCR extractor loaded")
        
        logger.info("Loading liveness detector...")
        from app.services.liveness_detector import get_liveness_detector
        liveness_detector = await asyncio.to_thread(get_liveness_detector)
        logger.info("âœ“ Liveness detector loaded")
        
        logger.info("âœ… All models loaded successfully")
    except ImportError as e:
        # ML libraries failed to import (e.g., onnxruntime not compatible)
        error_msg = f"ML libraries not available: {str(e)}"
        ml_import_error = error_msg
        logger.error(f"âš ï¸ {error_msg}")
    
    yield  # Server starts here
    
    # Cleanup on shutdown
    logger.info("Shutting down...")
    # Add cleanup code here if needed


# ============================================================================
# FastAPI Application
# ============================================================================

app = FastAPI(
    title="KYC Verification API",
    description="Face matching and OCR extraction for KYC verification",
    version=config.get("project", "version", default="1.0.0"),
    lifespan=lifespan
)

# CORS configuration
cors_origins = config.cors_origins
app.add_middleware(
    CORSMiddleware,
    allow_origins=cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ============================================================================
# Exception Handlers
# ============================================================================

@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    return JSONResponse(
        status_code=exc.status_code,
        content=ErrorResponse(
            error=exc.__class__.__name__,
            message=str(exc.detail),
            details=None
        ).model_dump(mode="json")
    )


@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    logger.error(f"Unhandled exception: {exc}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content=ErrorResponse(
            error="InternalServerError",
            message="An unexpected error occurred",
            details={"type": type(exc).__name__}
        ).model_dump(mode="json")
    )


# ============================================================================
# Utility Functions
# ============================================================================

async def read_upload_file(upload_file: UploadFile) -> np.ndarray:
    """Read and validate uploaded image file."""
    max_size = config.max_upload_size
    content = await upload_file.read()
    
    if len(content) > max_size:
        raise HTTPException(
            status_code=status.HTTP_413_REQUEST_ENTITY_TOO_LARGE,
            detail=f"File too large. Max size: {max_size / (1024*1024):.1f}MB"
        )
    
    try:
        nparr = np.frombuffer(content, np.uint8)
        image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if image is None:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Invalid image format. Supported: JPG, PNG"
            )
        
        max_dim = config.get("upload", "image_max_dimension", default=4096)
        h, w = image.shape[:2]
        if h > max_dim or w > max_dim:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"Image too large. Max dimension: {max_dim}px"
            )
        
        return image
    
    except Exception as e:
        if isinstance(e, HTTPException):
            raise
        logger.error(f"Image decode error: {e}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Failed to decode image"
        )


def determine_verification_status(face_verified: bool, ocr_confidence: float) -> VerificationStatus:
    """
    Determine overall verification status based on face match and OCR confidence.
    """
    if not face_verified:
        return VerificationStatus.REJECTED
    
    if ocr_confidence < 0.5:
        return VerificationStatus.PENDING  # Low OCR confidence, manual review
    
    return VerificationStatus.APPROVED


def calculate_confidence_score(
    face_confidence: float,
    ocr_confidence: float,
    face_verified: bool
) -> float:
    """
    Calculate overall confidence score (weighted: 60% face + 40% OCR).
    Used by frontend for display.
    """
    if not face_verified:
        return 0.0
    
    # Weighted average
    return (0.6 * face_confidence) + (0.4 * ocr_confidence)


# ============================================================================
# API Endpoints
# ============================================================================

@app.get("/api/v1/health", response_model=HealthCheckResponse, tags=["Health"])
async def health_check():
    """
    Health check endpoint with model status.
    """
    models_status = {}
    
    # Check face detector
    models_status["face_detector"] = ModelStatus(
        loaded=face_detector is not None,
        name="yunet",
        error=ml_import_error if face_detector is None else None
    )
    
    # Check face matcher
    models_status["face_matcher"] = ModelStatus(
        loaded=face_matcher is not None,
        name="insightface",
        error=ml_import_error if face_matcher is None else None
    )
    
    # Check OCR extractor
    models_status["ocr_extractor"] = ModelStatus(
        loaded=ocr_extractor is not None,
        name="easyocr",
        error=ml_import_error if ocr_extractor is None else None
    )
    
    # Check liveness detector
    models_status["liveness_detector"] = ModelStatus(
        loaded=liveness_detector is not None,
        name="mediapipe+haar",
        error=ml_import_error if liveness_detector is None else None
    )
    
    all_loaded = all(m.loaded for m in models_status.values())
    
    return HealthCheckResponse(
        status="healthy" if all_loaded else "degraded",
        version=config.get("project", "version", default="1.0.0"),
        models=models_status
    )


@app.post(
    "/api/v1/kyc/verify",
    response_model=KYCVerificationResponse,
    responses={400: {"model": ErrorResponse}, 500: {"model": ErrorResponse}},
    tags=["KYC"]
)
async def verify_kyc(
    id_document: UploadFile = File(..., description="ID card/passport image"),
    selfie_image: UploadFile = File(..., description="Selfie photo")
):
    """
    Complete KYC verification: face detection + matching + OCR.
    """
    start_time = time.time()
    
    if not all([face_detector, face_matcher, ocr_extractor]):
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Service not ready. Models still loading."
        )
    
    async with processing_semaphore:
        try:
            logger.info("Reading uploaded files...")
            id_image = await read_upload_file(id_document)
            selfie_img = await read_upload_file(selfie_image)
            
            # Detect faces
            logger.info("Detecting faces...")
            id_face_result, selfie_face_result = await asyncio.gather(
                asyncio.to_thread(face_detector.detect_and_extract, id_image),
                asyncio.to_thread(face_detector.detect_and_extract, selfie_img)
            )
            
            if id_face_result is None:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="No face detected in ID document"
                )
            
            if selfie_face_result is None:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="No face detected in selfie image"
                )
            
            # âœ… OPTIMIZATION: Run face matching and OCR in parallel
            logger.info("Running face matching and OCR in parallel...")
            match_result, ocr_result = await asyncio.gather(
                asyncio.to_thread(
                    face_matcher.verify,
                    id_face_result.face_crop,
                    selfie_face_result.face_crop
                ),
                asyncio.to_thread(
                    ocr_extractor.extract_structured,
                    id_image
                )
            )
            
            # Determine verification status
            verification_status = determine_verification_status(
                face_verified=match_result.verified,
                ocr_confidence=ocr_result.confidence
            )
            
            # âœ… FIX #2: Calculate overall confidence score for frontend
            confidence_score = calculate_confidence_score(
                face_confidence=match_result.confidence,
                ocr_confidence=ocr_result.confidence,
                face_verified=match_result.verified
            )
            
            processing_time_ms = int((time.time() - start_time) * 1000)
            
            logger.info(f"âœ“ Verification complete: {verification_status.value} (confidence: {confidence_score:.2f})")
            
            # Convert OCRResult to OCRData (Pydantic model)
            # All fields are Optional, so missing fields will be None - this handles documents with incomplete data
            ocr_fields = OCRFields(
                full_name=ocr_result.full_name,
                date_of_birth=ocr_result.date_of_birth,
                document_number=ocr_result.document_number,
                nationality=ocr_result.nationality,
                issue_date=ocr_result.issue_date,
                expiry_date=ocr_result.expiry_date,
                place_of_birth=ocr_result.place_of_birth,
                address=ocr_result.address,
                gender=ocr_result.gender
            )
            
            ocr_data = OCRData(
                document_type=ocr_result.document_type,
                confidence=ocr_result.confidence,
                extracted_text=ocr_result.extracted_text,
                fields=ocr_fields
            )
            
            return KYCVerificationResponse(
                verification_status=verification_status,
                confidence_score=confidence_score,
                face_match_score=match_result.confidence,
                ocr_data=ocr_data,
                processing_time_ms=processing_time_ms,
                face_verification_details=match_result.to_dict()
            )
        
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Verification error: {e}", exc_info=True)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Verification failed: {str(e)}"
            )


@app.post(
    "/api/v1/ocr/extract",
    response_model=OCROnlyResponse,
    responses={400: {"model": ErrorResponse}, 500: {"model": ErrorResponse}},
    tags=["OCR"]
)
async def extract_ocr(
    document: UploadFile = File(..., description="Document image for OCR extraction")
):
    """
    OCR-only endpoint: Extract text from document without face verification.
    """
    start_time = time.time()
    
    if ocr_extractor is None:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="OCR service not ready. Models still loading."
        )
    
    async with processing_semaphore:
        try:
            logger.info("Reading uploaded document...")
            doc_image = await read_upload_file(document)
            
            logger.info("Extracting OCR...")
            ocr_result = await asyncio.to_thread(
                ocr_extractor.extract_structured,
                doc_image
            )
            
            processing_time_ms = int((time.time() - start_time) * 1000)
            
            response = OCROnlyResponse(
                ocr_data=OCRData(
                    document_type=ocr_result.document_type,
                    confidence=ocr_result.confidence,
                    extracted_text=ocr_result.extracted_text,
                    fields=OCRFields(**{
                        k: v for k, v in ocr_result.to_dict().items()
                        if k in OCRFields.model_fields
                    })
                ),
                processing_time_ms=processing_time_ms
            )
            
            logger.info(f"âœ“ OCR extraction complete ({processing_time_ms}ms)")
            return response
        
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"OCR error: {e}", exc_info=True)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"OCR extraction failed: {str(e)}"
            )


# ============================================================================
# Liveness Detection Endpoints
# ============================================================================

def decode_base64_image(base64_str: str) -> np.ndarray:
    """
    Decode base64 image string to numpy array.
    
    Args:
        base64_str: Base64-encoded image (with or without data URI prefix)
    
    Returns:
        Decoded image as numpy array (BGR format)
    """
    import base64
    from io import BytesIO
    from PIL import Image
    
    # Remove data URI prefix if present
    if ',' in base64_str:
        base64_str = base64_str.split(',')[1]
    
    try:
        # Decode base64
        image_data = base64.b64decode(base64_str)
        
        # Convert to PIL Image
        pil_image = Image.open(BytesIO(image_data))
        
        # Convert to RGB if needed
        if pil_image.mode != 'RGB':
            pil_image = pil_image.convert('RGB')
        
        # Convert to numpy array (RGB)
        img_array = np.array(pil_image)
        
        # Convert RGB to BGR for OpenCV
        img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
        
        return img_bgr
    
    except Exception as e:
        logger.error(f"Base64 decode error: {e}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Failed to decode base64 image: {str(e)}"
        )


@app.get(
    "/api/v1/liveness/challenge",
    response_model=ChallengeResponse,
    tags=["Liveness"]
)
async def generate_challenge():
    """
    Generate a new liveness challenge.
    Returns a challenge that the user must complete (blink, turn left, turn right).
    """
    try:
        from app.services.liveness_challenges import get_challenge_generator
        
        generator = get_challenge_generator()
        challenge = generator.generate_challenge()
        
        logger.info(f"Generated challenge: {challenge.challenge_type.value} (ID: {challenge.challenge_id})")
        
        return ChallengeResponse(**challenge.to_dict())
    
    except Exception as e:
        logger.error(f"Challenge generation error: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to generate challenge: {str(e)}"
        )


@app.post(
    "/api/v1/liveness/verify",
    response_model=LivenessVerificationResponse,
    responses={400: {"model": ErrorResponse}, 500: {"model": ErrorResponse}},
    tags=["Liveness"]
)
async def verify_liveness_challenge(request: LivenessVerificationRequest):
    """
    Verify a liveness challenge with captured frames.
    Processes frames and validates against the challenge requirements.
    """
    start_time = time.time()
    
    if liveness_detector is None:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Liveness detector not available. Service may still be loading."
        )
    
    async with processing_semaphore:
        try:
            # Validate request
            if not request.frames or len(request.frames) == 0:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="No frames provided"
                )
            
            min_frames = config.get("liveness", "detection", "min_frames", default=10)
            if len(request.frames) < min_frames:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail=f"Not enough frames. Minimum: {min_frames}, received: {len(request.frames)}"
                )
            
            logger.info(f"Verifying challenge {request.challenge_id} with {len(request.frames)} frames...")
            
            # Decode base64 frames
            decoded_frames = []
            for i, frame_str in enumerate(request.frames):
                try:
                    frame = decode_base64_image(frame_str)
                    decoded_frames.append(frame)
                except Exception as e:
                    logger.warning(f"Failed to decode frame {i}: {e}")
                    # Continue with other frames
            
            if len(decoded_frames) == 0:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="Failed to decode any frames"
                )
            
            # Verify challenge
            status_result, message, results = await asyncio.to_thread(
                liveness_detector.verify_challenge,
                request.challenge_id,
                decoded_frames,
                0,  # initial_counter
                0   # initial_total
            )
            
            processing_time_ms = int((time.time() - start_time) * 1000)
            
            logger.info(f"Challenge verification: {status_result.value} - {message}")
            
            return LivenessVerificationResponse(
                challenge_id=request.challenge_id,
                status=status_result,
                message=message,
                detection_results=results.get("detection_results", {}),
                processing_time_ms=processing_time_ms
            )
        
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Liveness verification error: {e}", exc_info=True)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Liveness verification failed: {str(e)}"
            )


@app.post(
    "/api/v1/liveness/detect",
    response_model=LivenessBatchResponse,
    responses={400: {"model": ErrorResponse}, 500: {"model": ErrorResponse}},
    tags=["Liveness"]
)
async def detect_liveness_batch(request: LivenessBatchRequest):
    """
    Perform batch liveness detection without challenge.
    Useful for continuous detection or testing.
    """
    start_time = time.time()
    
    if liveness_detector is None:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Liveness detector not available. Service may still be loading."
        )
    
    async with processing_semaphore:
        try:
            # Validate request
            if not request.frames or len(request.frames) == 0:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="No frames provided"
                )
            
            logger.info(f"Processing batch liveness detection with {len(request.frames)} frames...")
            
            # Decode base64 frames
            decoded_frames = []
            for i, frame_str in enumerate(request.frames):
                try:
                    frame = decode_base64_image(frame_str)
                    decoded_frames.append(frame)
                except Exception as e:
                    logger.warning(f"Failed to decode frame {i}: {e}")
                    # Continue with other frames
            
            if len(decoded_frames) == 0:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="Failed to decode any frames"
                )
            
            # Detect liveness
            batch_results = await asyncio.to_thread(
                liveness_detector.detect_batch,
                decoded_frames,
                0,  # initial_counter
                request.initial_blink_count  # initial_total
            )
            
            processing_time_ms = int((time.time() - start_time) * 1000)
            
            return LivenessBatchResponse(
                total_blinks=batch_results.get("total_blinks", 0),
                final_blink_count=batch_results.get("final_blink_count", 0),
                orientations=batch_results.get("orientations", []),
                face_detection_ratio=batch_results.get("face_detection_ratio", 0.0),
                results=batch_results.get("results", []),
                frame_count=batch_results.get("frame_count", len(decoded_frames)),
                processing_time_ms=processing_time_ms
            )
        
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Batch liveness detection error: {e}", exc_info=True)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Batch liveness detection failed: {str(e)}"
            )
